{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# orchestration engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple coroutine for the sake of illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def mycoro(timeout):\n",
    "    print(\"-> {} mycoro({})\".format(time.strftime(\"%H:%M:%S\"), timeout))\n",
    "    await asyncio.sleep(timeout)\n",
    "    print(\"<- {} mycoro({})\".format(time.strftime(\"%H:%M:%S\"), timeout))\n",
    "    # return something easy to recognize\n",
    "    return 1000 * timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a series of coroutines in parallel - a la `gather` - can be done like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from job import Job\n",
    "from engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1, a2, a3 = Job(mycoro(1)), Job(mycoro(2)), Job(mycoro(1.5)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're saying here is that we have three jobs, that have no relationships between them. \n",
    "\n",
    "So when we run them, we would start all 3 coroutines at once, and return once they are all done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 19:31:22 mycoro(1.5)\n",
      "-> 19:31:22 mycoro(2)\n",
      "-> 19:31:22 mycoro(1)\n",
      "<- 19:31:23 mycoro(1)\n",
      "<- 19:31:24 mycoro(1.5)\n",
      "<- 19:31:24 mycoro(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ea = Engine(a1, a2, a3)\n",
    "ea.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example B : add requirements (dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add *requirements* dependencies between jobs, like in the following example. We take this chance to show that jobs can be tagged with a label, which can turn out te be convenient somtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1, b2, b3 = (Job(mycoro(1), label=\"b1\"),\n",
    "              Job(mycoro(2)), \n",
    "              Job(mycoro(1.5), label=\"b3\"))\n",
    "\n",
    "b3.requires(b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `b3` needs `b1` to be finished before it can start. And so only the 2 first coroutines get started at the beginning, and only once b1 has finished does b3 start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eb = Engine(b1, b2, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 19:31:24 mycoro(2)\n",
      "-> 19:31:24 mycoro(1)\n",
      "<- 19:31:25 mycoro(1)\n",
      "-> 19:31:25 mycoro(1.5)\n",
      "<- 19:31:26 mycoro(2)\n",
      "<- 19:31:27 mycoro(1.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eb.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect results\n",
    "\n",
    "Before we see more examples, let's see how details for each `Job` can be retrieved once `orchestrate` finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Job `NOLABEL' finished -> 2000>\n",
      "<Job `b3' finished -> 1500.0 - [requires [b1]]>\n",
      "<Job `b1' finished -> 1000 - [allows [b3]]>\n"
     ]
    }
   ],
   "source": [
    "# a shorter equivalent form would be \n",
    "# e2.list()\n",
    " \n",
    "for job in eb.jobs:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(b1.is_done())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500.0\n"
     ]
    }
   ],
   "source": [
    "print(b3.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example C : infinite loops, or coroutines that don't return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to deal with a endless loop; for example if we want to separate completely actions and printing, we can use an `asyncio.Queue` to implement a simple message bus as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_bus = asyncio.Queue()\n",
    "\n",
    "async def monitor_loop(bus):\n",
    "    while True:\n",
    "        message = await bus.get()\n",
    "        print(\"{} BUS: {}\".format(time.strftime(\"%H:%M:%S\"), message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a modified version of the previous coroutine, that interacts with this message bus instead of printing anything itself&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def mycoro_bus(timeout, bus):\n",
    "    await bus.put(\"-> mycoro({})\".format(timeout))\n",
    "    await asyncio.sleep(timeout)\n",
    "    await bus.put(\"<- mycoro({})\".format(timeout))\n",
    "    # return something easy to recognize\n",
    "    return 10 * timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replay the prevous scenario, adding the monitoring loop as a separate job; however we need to declare this job with `forever=True` so that we know when the bulk of the scenario is completed, since the monitoring loop will never return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:31:27 BUS: -> mycoro(0.8)\n",
      "19:31:27 BUS: -> mycoro(0.4)\n",
      "19:31:27 BUS: <- mycoro(0.4)\n",
      "19:31:27 BUS: -> mycoro(0.6)\n",
      "19:31:28 BUS: <- mycoro(0.8)\n",
      "19:31:28 BUS: <- mycoro(0.6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2, c3, c4 = (Job(mycoro_bus(0.4, message_bus), label=\"c1\"),\n",
    "                  Job(mycoro_bus(0.8, message_bus), label=\"c2\"), \n",
    "                  Job(mycoro_bus(0.6, message_bus), label=\"c3\"),\n",
    "                  Job(monitor_loop(message_bus), forever=True, label=\"monitor\"))\n",
    "\n",
    "c3.requires(c1)\n",
    "\n",
    "ec = Engine(c1, c2, c3, c4)\n",
    "ec.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `orchestrate` always terminates as soon as all the non-`forever` jobs are complete. The `forever` jobs, on the other hand, get cancelled, so of course no return value is available at the end of the scenario&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <Job `monitor'[∞] cancelled>\n",
      "1 <Job `c2' finished -> 8.0>\n",
      "2 <Job `c3' finished -> 6.0 - [requires [c1]]>\n",
      "3 <Job `c1' finished -> 4.0 - [allows [c3]]>\n"
     ]
    }
   ],
   "source": [
    "ec.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example D : specifying a global timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`orchestrate` accepts a `timeout` argument in seconds. When provided, `orchestrate` will ensure its global duration does not exceed this value, and will return `False` if the timeout triggers.\n",
    "\n",
    "Of course this can be used with any number of jobs and dependencies, but for the sake of simplicity let us see this in action with just one job that loops forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:31:28: forever 0\n",
      "19:31:29: forever 1\n",
      "19:31:30: forever 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def forever():\n",
    "    for i in range(100000):\n",
    "        print(\"{}: forever {}\".format(time.strftime(\"%H:%M:%S\"), i))\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "j = Job(forever(), forever=True)\n",
    "e = Engine(j)\n",
    "e.orchestrate(timeout=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the result of `orchestrate` in this case is `False`, since not all jobs have completed. Apart from that the jobs is now in this state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Job `NOLABEL'[∞] cancelled>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# customizing the `Job` class\n",
    "\n",
    "`Job` actually is a specializtion of `AbstractJob`, and the specification is that the `corun()` method should denote a coroutine itself, and that is what is triggered by `Engine` for running said job.\n",
    "\n",
    "You can define your own `Job` class by specializing `job.AbstractJob` - more on this later, we'll define some predefined jobs, in particular for interacting through ssh, and possibly many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "This totally is only a seed at this point, like day d+1 \n",
    "\n",
    "## deal with exceptions\n",
    "* for now we kind of assume that `corun()` does not trigger an exception. This needs to be robustified. \n",
    "\n",
    "## termination\n",
    "\n",
    "1. provide a means to tidy up jobs once the engine has run out. Typically we would have several jobs using the same ssh connection, and these need to be closed at some point. Something like `Engine.shutdown` sending `Job.coshutdown()`, or similar...\n",
    "\n",
    "  Would it work to just send e.g. `coshutdown()` on all jobs ? this needs a little more thinking though; that could mean trying to shutdown an ssh connection from several points at the same time ...\n",
    "\n",
    "\n",
    "## monitoring \n",
    "* come up with some basic (curses ?) monitor to show what's going on; what I have in mind is something like rhubarbe load where all jobs would be displayed, one line each, and their status could be shown so that one can get a sense of what is going on\n",
    "* one way to look at this is to have the main Engine class send itself a `tick()` method, and then specialize `Engine` as `EngineCurses` that would actually do things on such events.\n",
    "* ***or*** this gets delegated on a `message_queue` object. **Review the rhubarbe code on this aspect**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
